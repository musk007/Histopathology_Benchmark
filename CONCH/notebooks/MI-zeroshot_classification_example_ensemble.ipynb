{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from conch.open_clip_custom import create_model_from_pretrained\n",
    "from conch.downstream.zeroshot_path import zero_shot_classifier, run_mizero\n",
    "from conch.downstream.wsi_datasets import WSIEmbeddingDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# display all jupyter output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('../').resolve()\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example for performing zero-shot classification by ensembling multiple prompts and prompt templates for WSIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_path = './checkpoints/CONCH/pytorch_model.bin'\n",
    "model, _ = create_model_from_pretrained(model_cfg='conch_ViT-B-16', checkpoint_path=checkpoint_path, device=device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_col = 'slide_id' # column with the slide ids\n",
    "target_col = 'OncoTreeCode' # column with the target labels\n",
    "label_map = {'LUAD': 0, 'LUSC': 1} # maps values in target_col to integers\n",
    "\n",
    "# assuming the csv has a column for slide_id (index_col) and OncoTreeCode (target_col), adjust above as needed\n",
    "df = pd.read_csv('path/to/csv')\n",
    "# path to the extracted embeddings, assumes the embeddings are saved as .pt files, 1 file per slide\n",
    "data_source = '/path/to/extracted-embeddings/' \n",
    "\n",
    "df = df[df[target_col].isin(label_map.keys())].reset_index(drop=True)\n",
    "\n",
    "dataset = WSIEmbeddingDataset(data_source = data_source,\n",
    "                              df=df,\n",
    "                              index_col=index_col,\n",
    "                              target_col=target_col,\n",
    "                              label_map=label_map)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=1, \n",
    "                        shuffle=False, \n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {v:k for k,v in dataloader.dataset.label_map.items()}\n",
    "print(\"num samples: \", len(dataloader.dataset))\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_file = './prompts/nsclc_prompts_all_per_class.json'\n",
    "with open(prompt_file) as f:\n",
    "    prompts = json.load(f)['0']\n",
    "classnames = prompts['classnames']\n",
    "templates = prompts['templates']\n",
    "n_classes = len(classnames)\n",
    "classnames_text = [classnames[str(idx_to_class[idx])] for idx in range(n_classes)]\n",
    "for class_idx, classname in enumerate(classnames_text):\n",
    "    print(f'{class_idx}: {classname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_weights = zero_shot_classifier(model, classnames_text, templates, device=device)\n",
    "print(zeroshot_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, dump = run_mizero(model, zeroshot_weights, dataloader, device, \n",
    "                    dump_results=True, metrics=['bacc', 'weighted_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_j_idx = np.argmax(list(results['bacc'].values()))\n",
    "best_j = list(results['bacc'].keys())[best_j_idx]\n",
    "for metric, metric_dict in results.items():\n",
    "    print(f\"{metric}: {metric_dict[best_j]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
